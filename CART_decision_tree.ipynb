{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART Decision Tree implemented by Shixun Wu, swu264"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pydotplus\n",
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class of the node \n",
    "class Node:\n",
    "    def __init__(self,):\n",
    "        self.child = [] # child\n",
    "        self.predict = None # class of this node\n",
    "        self.gini = 0 # gini index of this node\n",
    "        self.label = None # label use to split\n",
    "        self.label_value = None # label value used to split\n",
    "        self.samples = 0 # number of instances at this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to do the greedy split\n",
    "# Loop over all features and corresponding feature values.\n",
    "# Select the feature and the value of the feature minimizes the Gini value\n",
    "def greedy_split_gini(x,y):\n",
    "    gini = 0\n",
    "    df = x.join(y)\n",
    "    min_gini = 100\n",
    "    label_value = None\n",
    "    size_ = x.columns.shape[0]\n",
    "    # Add random permutation to loop over features\n",
    "    perm = np.array([i for i in range(size_)])\n",
    "    perm = np.random.permutation(perm)\n",
    "    \n",
    "    # Loop over features\n",
    "    for i in perm:\n",
    "        label = x.columns[i]\n",
    "        label_stat = df[label].value_counts()\n",
    "        s = label_stat.sum()\n",
    "        # Random choice different values of the feature i\n",
    "        perm_index = np.array([j for j in range(label_stat.index.shape[0])])\n",
    "        perm_index = np.random.choice(perm_index, min(10,label_stat.index.shape[0]) , replace=False)\n",
    "        # Loop over the choosed values\n",
    "        for j in perm_index:\n",
    "            if label_stat.index.shape[0] == 2:\n",
    "                key = (label_stat.index[0] + label_stat.index[1]) / 2\n",
    "            else:\n",
    "                key = label_stat.index[j]\n",
    "            tmp = ((df[df[label] <= key])['Label']).value_counts()\n",
    "            if tmp.size > 0:\n",
    "                value = tmp.sum()\n",
    "                p = tmp.values[0] / tmp.sum()\n",
    "                gini = value / s * (1 - p ** 2 - (1-p) ** 2)\n",
    "            tmp = ((df[df[label] > key])['Label']).value_counts()\n",
    "            if tmp.size > 0:\n",
    "                p = tmp.values[0] / tmp.sum()\n",
    "                value = tmp.sum()\n",
    "                gini += value / s * (1 - p ** 2 - (1-p) ** 2)\n",
    "            # update the min gini if gini < min_gini\n",
    "            if gini <= min_gini:\n",
    "                label_ = label\n",
    "                label_value = key\n",
    "                min_gini = gini\n",
    "    return label_, label_value, min_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to build the tree\n",
    "# Recursive call this function in a DFS way\n",
    "# In this function:\n",
    "#   0. Preprocessing to initilize the current node.\n",
    "#   1. Call greedy_split_gini to find the best partition\n",
    "#   2. If the weighted sum of the Gini-index of the best partition >= Gini-index at current node, \n",
    "#      then mark this node as a leaf node and return.\n",
    "#   3. Else:\n",
    "#          build_dfs(left_child_node)\n",
    "#          build_dfs(right_child_node)\n",
    "#   4. Return    \n",
    "def build_dfs(x, y, parent_num_no_ob, parent_num_ob, dp):\n",
    "    #   0. Preprocessing to initilize the current node.\n",
    "    node = Node()\n",
    "    label_ = None\n",
    "    tmp = y.value_counts()\n",
    "    predict_if_leaf = False\n",
    "    num_no_obesity = 0\n",
    "    num_obesity = 0\n",
    "    for key in tmp.index:\n",
    "        if key == 0.0:\n",
    "            num_no_obesity = tmp.loc[key]\n",
    "        else:\n",
    "            num_obesity = tmp.loc[key]\n",
    "    if (num_no_obesity / parent_num_no_ob) >= ( num_obesity / parent_num_ob):\n",
    "        predict_if_leaf = False\n",
    "    else:\n",
    "        predict_if_leaf = True\n",
    "    p = tmp.values[0] / tmp.sum()\n",
    "    gini_if_leaf = (1 - p ** 2 - (1-p) ** 2)\n",
    "    \n",
    "    #   1. Call greedy_split_gini to find the best partition\n",
    "    label_, label_value, min_gini = greedy_split_gini(x,y)\n",
    "    node.samples = num_obesity + num_no_obesity\n",
    "    \n",
    "    #   2. If the weighted sum of the Gini-index of the best partition >= Gini-index at current node, \n",
    "    #      then mark this node as a leaf node and return.\n",
    "    \n",
    "    if gini_if_leaf <= min_gini:\n",
    "        node.label = label_\n",
    "        node.predict = predict_if_leaf\n",
    "        node.gini = gini_if_leaf\n",
    "        node.label_value = label_value\n",
    "        return node\n",
    "    else:\n",
    "    #   3. Else:\n",
    "    #       build_dfs(left_child_node)\n",
    "    #       build_dfs(right_child_node)\n",
    "        node.label = label_\n",
    "        node.predict = None\n",
    "        node.gini = gini_if_leaf\n",
    "        node.label_value = label_value\n",
    "        # build left child node\n",
    "        index = x.index[x[label_] <= label_value]\n",
    "        child_node = build_dfs(x.loc[index], y.loc[index], num_no_obesity, num_obesity, dp+1)\n",
    "        node.child.append(child_node)\n",
    "        # build right child node \n",
    "        index = x.index[x[label_] > label_value]\n",
    "        child_node = build_dfs(x.loc[index], y.loc[index], num_no_obesity, num_obesity, dp+1)\n",
    "        node.child.append(child_node)\n",
    "    #   4. Return  \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the data and perform preprocessing\n",
    "# Map frequency adverb to integer\n",
    "# Round up float into classes of integer\n",
    "def preprocessing(if_sklearn=True) -> pd.DataFrame:\n",
    "    df = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
    "    # df = df.loc[:10 * b]\n",
    "    df['Label'] = df['NObeyesdad'].str.startswith('Obesity').astype(int)\n",
    "    del df['NObeyesdad']\n",
    "    del df['Height']\n",
    "    del df['Weight']\n",
    "\n",
    "    freq_map = {'no': 0, 'Sometimes': 1,\n",
    "    'Frequently': 2, 'Always': 3}\n",
    "    yes_no_map = {'yes': 1, 'no': 0}\n",
    "    df['Age'] = (df['Age']).round()\n",
    "    df['NCP'] = (df['NCP'] * 10).round()\n",
    "    df['CH2O'] = (df['CH2O'] * 10).round() #/ 10\n",
    "    df['FAF'] = (df['FAF'] * 10).round() #/ 10\n",
    "    df['TUE'] = (df['TUE'] * 10).round() #/ 10\n",
    "    df['FCVC'] = (df['FCVC'] * 10).round() #/ 10\n",
    "    df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    df['family_history_with_overweight'] = df['family_history_with_overweight'].map(yes_no_map)\n",
    "    df['FAVC'] = df['FAVC'].map(yes_no_map)\n",
    "    df['CAEC'] = df['CAEC'].map(freq_map)\n",
    "    df['SMOKE'] = df['SMOKE'].map(yes_no_map)\n",
    "    df['SCC'] = df['SCC'].map(yes_no_map)\n",
    "    df['CALC'] = df['CALC'].map(freq_map)\n",
    "    \n",
    "    df['MTRANS'] = df['MTRANS'].map({'Automobile': 0, 'Motorbike': 0, 'Public_Transportation': 0, 'Walking': 1, 'Bike': 1})\n",
    "    normalized_df = (df-df.min())/(df.max()-df.min())\n",
    "    df = normalized_df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the tree\n",
    "# Change my class node and the decision tree into \"dot language\"\n",
    "def dotgraph(decisionTree):\n",
    "    global dcHeadings\n",
    "    dcNodes = defaultdict(list)\n",
    "    \"\"\"Plots the obtained decision tree. \"\"\"\n",
    "\n",
    "    def toString(iSplit, decisionTree, bBranch, szParent=\"null\", indent=''):\n",
    "        if decisionTree.predict != None:  # leaf node\n",
    "            lsY = []\n",
    "            \n",
    "            lsY.append(f'result:{decisionTree.predict}')\n",
    "            dcY = {\"name\": \"%s\" % ', '.join(lsY), \"parent\": szParent}\n",
    "            \n",
    "            dcNodes[iSplit].append(['leaf', dcY['name'], szParent, bBranch, f\"{decisionTree.gini:.3f}\",\n",
    "                                    decisionTree.samples])\n",
    "            return dcY\n",
    "        else:\n",
    "            szCol = decisionTree.label\n",
    "            \n",
    "            decision = f\"{szCol} less than {decisionTree.label_value:.3f}\"\n",
    "            \n",
    "            trueBranch = toString(iSplit + 1, decisionTree.child[0], True, decision, indent + '\\t\\t')\n",
    "            falseBranch = toString(iSplit + 1, decisionTree.child[1], False, decision, indent + '\\t\\t')\n",
    "            \n",
    "            dcNodes[iSplit].append([iSplit + 1, decision, szParent, bBranch, f\"{decisionTree.gini:.3f}\",\n",
    "                                    decisionTree.samples])\n",
    "            return\n",
    "\n",
    "    toString(0, decisionTree, None)\n",
    "    lsDot = ['digraph Tree {',\n",
    "             'node [shape=box, style=\"filled, rounded\", color=\"black\", fontname=helvetica] ;',\n",
    "             'edge [fontname=helvetica] ;'\n",
    "             ]\n",
    "    i_node = 0\n",
    "    dcParent = {}\n",
    "    for nSplit in range(len(dcNodes)):\n",
    "        lsY=dcNodes[nSplit]\n",
    "        for lsX in lsY:\n",
    "            iSplit, decision, szParent, bBranch, szImpurity, szSamples = lsX\n",
    "            if type(iSplit) == int:\n",
    "                szSplit = '%d-%s' % (iSplit, decision)\n",
    "                dcParent[szSplit] = i_node\n",
    "                lsDot.append('%d [label=<%s<br/>impurity %s<br/>samples %s>, fillcolor=\"#e5813900\"] ;' % (i_node,\n",
    "                                                                                                          decision.replace(\n",
    "                                                                                                              '>=',\n",
    "                                                                                                              '&ge;').replace(\n",
    "                                                                                                              '?', ''),\n",
    "                                                                                                          szImpurity,\n",
    "                                                                                                          szSamples))\n",
    "            else:\n",
    "                lsDot.append('%d [label=<impurity %s<br/>samples %s<br/>class %s>, fillcolor=\"#e5813900\"] ;' % (i_node,\n",
    "                                                                                                                szImpurity,\n",
    "                                                                                                                szSamples,\n",
    "                                                                                                                decision))\n",
    "\n",
    "            if szParent != 'null':\n",
    "                if bBranch:\n",
    "                    szAngle = '45'\n",
    "                    szHeadLabel = 'True'\n",
    "                else:\n",
    "                    szAngle = '-45'\n",
    "                    szHeadLabel = 'False'\n",
    "                szSplit = '%d-%s' % (nSplit, szParent)\n",
    "                p_node = dcParent[szSplit]\n",
    "                if nSplit == 1:\n",
    "                    lsDot.append('%d -> %d [labeldistance=2.5, labelangle=%s, headlabel=\"%s\"] ;' % (p_node,\n",
    "                                                                                                    i_node, szAngle,\n",
    "                                                                                                    szHeadLabel))\n",
    "                else:\n",
    "                    lsDot.append('%d -> %d ;' % (p_node, i_node))\n",
    "            i_node += 1\n",
    "    lsDot.append('}')\n",
    "    dot_data = '\\n'.join(lsDot)\n",
    "    return dot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call preprocessing to read the data \n",
    "df = preprocessing()\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "cnt = 0\n",
    "sklearn_result = []\n",
    "result = []\n",
    "k = 0\n",
    "\n",
    "skf = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=0)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # if k == 0:\n",
    "    node = build_dfs(X_train, y_train, 1, 1, 1)\n",
    "    dot_data = dotgraph(node)\n",
    "    \n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    graph.write_pdf(\"my_CART.pdf\")\n",
    "    \n",
    "    k += 1\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    tree.plot_tree(clf)\n",
    "    dot_data = tree.export_graphviz(clf, feature_names=X_train.columns,  \n",
    "                            class_names=[\"Healthy\", \"Obesity\"],out_file=None) \n",
    "    graph = graphviz.Source(dot_data) \n",
    "    graph.render(\"sklearn_CART\") \n",
    "    \n",
    "    y_pred_sklearn = clf.predict(X_test)\n",
    "    \n",
    "    sklearn_result.append({\"accuracy\":accuracy_score(y_test, y_pred_sklearn),\n",
    "                        \"precision\":precision_score(y_test, y_pred_sklearn),\n",
    "                        \"recall\":recall_score(y_test, y_pred_sklearn),\n",
    "                        \"f1\":f1_score(y_test, y_pred_sklearn),\n",
    "                        \"confusion\":confusion_matrix(y_test, y_pred_sklearn)})\n",
    "    print(\"sklearn result:\", sklearn_result[-1])\n",
    "    \n",
    "    y_pred = np.zeros(y_pred_sklearn.shape[0])\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        node_ = node\n",
    "        while (len(node_.child) > 0):\n",
    "            if len(node_.child) > 0:\n",
    "                if (X_test.iloc[i])[node_.label] <= node_.label_value:\n",
    "                    node_ = node_.child[0]\n",
    "                else:\n",
    "                    node_ = node_.child[1]      \n",
    "        if node_.predict == False and y_test.iloc[i] == 0.0:\n",
    "            cnt += 1\n",
    "        if node_.predict == True and y_test.iloc[i] != 0.0:\n",
    "            cnt += 1\n",
    "        y_pred[i] = int(node_.predict)\n",
    "    result.append({\"accuracy\":accuracy_score(y_test, y_pred),\n",
    "                        \"precision\":precision_score(y_test, y_pred),\n",
    "                        \"recall\":recall_score(y_test, y_pred),\n",
    "                        \"f1\":f1_score(y_test, y_pred),\n",
    "                        \"confusion\":confusion_matrix(y_test, y_pred)})\n",
    "    print(\"result:\", result[-1])\n",
    "    with open(\"sklearn_result.pkl\", \"wb\") as f:\n",
    "        pkl.dump(sklearn_result, f)\n",
    "    with open(\"result.pkl\", \"wb\") as f:\n",
    "        pkl.dump(result, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fec15aaf15af2f7b25d7149644915fb0538c5beb7ab358bd639337cd8050469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
