{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Student Information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "|Name|NetId|\n",
    "|-|-|\n",
    "|Xing Gao|xgao058|"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some libraries should be imported first:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shared code\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load our dataset into a dataframe:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shared code\n",
    "df = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get `X` (a matrix of the features values) and `y` (a vector of the labels) from the dataframe:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shared code\n",
    "y: pd.Series = df['NObeyesdad'].str.startswith('Obesity').astype(int)\n",
    "del df['NObeyesdad']\n",
    "del df['Height']\n",
    "del df['Weight']\n",
    "X: pd.DataFrame = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy, precision, recall and f1 are our metrics:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shared code\n",
    "def evaluate(y_actual, y_pred):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    print('accuracy:', accuracy_score(y_actual, y_pred))\n",
    "    print('precision:', precision_score(y_actual, y_pred))\n",
    "    print('recall:', recall_score(y_actual, y_pred))\n",
    "    print('f1:', f1_score(y_actual, y_pred))\n",
    "    print('confusion matrix:')\n",
    "    print(confusion_matrix(y_actual, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since perceptron only accepts numeric values, I need to map categorical values to numeric ones.\n",
    "For `MTRANS` feature, I believe the number reflects the amount of exercise.\n",
    "\n",
    "Then normalize all features using min-max."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocessing() -> pd.DataFrame:\n",
    "\n",
    "    freq_map = {'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3}\n",
    "    yes_no_map = {'yes': 1, 'no': 0}\n",
    "    #\n",
    "    df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    df['family_history_with_overweight'] = df['family_history_with_overweight'].map(yes_no_map)\n",
    "    df['FAVC'] = df['FAVC'].map(yes_no_map)\n",
    "    df['CAEC'] = df['CAEC'].map(freq_map)\n",
    "    df['SMOKE'] = df['SMOKE'].map(yes_no_map)\n",
    "    df['SCC'] = df['SCC'].map(yes_no_map)\n",
    "    df['CALC'] = df['CALC'].map(freq_map)\n",
    "    df['MTRANS'] = df['MTRANS'].map(\n",
    "        {'Automobile': 0, 'Motorbike': 0, 'Public_Transportation': 0, 'Walking': 1, 'Bike': 1})\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## My Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want to compare the probability of the data belonging to each class.  Using Bayes' theorem, the probability can be decomposed as($Y$ is the classes $X$ is the attribute) :\n",
    "\n",
    "$$P(Y|X) = \\frac{P(X|Y)P(Y)}{P(X)} $$\n",
    "\n",
    "$c$ is the classes, $ x = \\{ a_1 ... a_n \\}$ is the attributes\n",
    "\n",
    "$$P(x|c) = \\sum_{j=1}^n P(a_j|c)$$\n",
    "\n",
    "We assume that all the data follow a Gaussian or normal distribution and then use the gaussian function to calculate the probability of the probability of likelihoods\n",
    "$a_j$ is the value of the attribute $j$, $\\mu_{c,j}$ and $\\sigma_{c,j}$ are the mean and squared deviation of the attribute $j$ of the class$c$ sample, respectively:\n",
    "\n",
    "\n",
    "$$P(a_j|c) = \\frac{1}{\\sqrt{2 \\pi \\sigma_{c,j}}} exp(-\\frac{(a_j-\\mu_{c,j})^2}{2\\sigma^2_{c,j}})$$\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def gauss(self, test, mean, std):\n",
    "        t1 = (test - mean) * (test - mean)\n",
    "        t2 = std * std\n",
    "        if t2 == 0:\n",
    "            t2 = 0.001\n",
    "        res = np.exp(-t1/(t2*2)) / np.sqrt(2*t2*np.pi)\n",
    "        # return np.log(res)\n",
    "        return res\n",
    "\n",
    "    def fit (self, x_train: np.ndarray, y_train: np.ndarray):\n",
    "        self.normalData = []\n",
    "        self.obesityData = []\n",
    "        self.norMean = []\n",
    "        self.norStd = []\n",
    "        self.obeMean = []\n",
    "        self.obeStd = []\n",
    "\n",
    "        for i in range(y_train.shape[0]):\n",
    "            if y_train[i] == 0:\n",
    "                self.normalData.append(x_train[i])\n",
    "            else:\n",
    "                self.obesityData.append(x_train[i])\n",
    "\n",
    "        self.normalData = np.array(self.normalData)\n",
    "        self.obesityData = np.array(self.obesityData)\n",
    "\n",
    "        self.norMean = self.normalData.mean(axis=0)\n",
    "        self.norStd = self.normalData.std(axis=0)\n",
    "        self.obeMean = self.obesityData.mean(axis=0)\n",
    "        self.obeStd = self.obesityData.std(axis=0)\n",
    "        self.norPY = (y_train.shape[0]- np.sum(y_train)) / y_train.shape[0]\n",
    "        self.obePY = np.sum(y_train)/ y_train.shape[0]\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self,x_test: np.ndarray):\n",
    "        y_prob = []\n",
    "\n",
    "        for i in range(x_test.shape[0]):\n",
    "            curNor = self.norPY\n",
    "            curObe = self.obePY\n",
    "            for j in range(x_test.shape[1]):\n",
    "                curNor *= self.gauss(x_test[i,j],self.norMean[j],self.norStd[j])\n",
    "                curObe *= self.gauss(x_test[i,j],self.obeMean[j],self.obeStd[j])\n",
    "            y_prob.append(int(curObe > curNor))\n",
    "\n",
    "            # pxy = np.prod(self.gauss(x_test))\n",
    "        print(y_prob)\n",
    "        print(y_test)\n",
    "\n",
    "        return np.array(y_prob)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To reduce the randomness of train_test_split, I split the dataset with 50 different random_states. For each split I train the off-the-shelf implementation and mine using the training set and predict the labels for the test set. I concatenate the $y_{actual}$ and $y_{pred}$ of each split and use them to compute the metrics.\n",
    "\n",
    "My implementation performs better than off-the-shelf on f1 score.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_naive_bayes(X,y):\n",
    "    # df = preprocessing()\n",
    "    # X = df.drop(columns=['Label'])\n",
    "    # y = df['Label']\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    X.astype(np.int32)\n",
    "    y.astype(np.int32)\n",
    "\n",
    "    myPredAll = np.empty(shape=(0,))\n",
    "    sklPredAll = np.empty(shape=(0,))\n",
    "    y_test_all = np.empty(shape=(0,))\n",
    "\n",
    "    for i in range(50):\n",
    "\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        y_test_all = np.append(y_test_all, y_test)\n",
    "\n",
    "        nb = NaiveBayes()\n",
    "        nb.fit(X_train,y_train)\n",
    "        myPred = nb.predict(X_test)\n",
    "        myPredAll = np.append(myPredAll,myPred)\n",
    "\n",
    "        clf = GaussianNB()\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        sklPred = clf.predict(X_test)\n",
    "        sklPredAll = np.append(sklPredAll, sklPred)\n",
    "\n",
    "    print('[+] off-the-shelf implementation:')\n",
    "    evaluate(y_test_all, sklPredAll)\n",
    "    print()\n",
    "\n",
    "    print('[+] my implementation:')\n",
    "    evaluate(y_test_all, myPredAll)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_naive_bayes(X.copy(),y.copy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "[+] off-the-shelf implementation:\n",
    "accuracy: 0.7536908517350158\n",
    "precision: 0.6609783845278726\n",
    "recall: 0.955068493150685\n",
    "f1: 0.7812640071716719\n",
    "confusion matrix:\n",
    "[[ 9948  7152]\n",
    " [  656 13944]]\n",
    "\n",
    "[+] my implementation:\n",
    "accuracy: 0.7566246056782334\n",
    "precision: 0.6640457469621158\n",
    "recall: 0.9544520547945206\n",
    "f1: 0.7831951665027399\n",
    "confusion matrix:\n",
    "[[10050  7050]\n",
    " [  665 13935]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}